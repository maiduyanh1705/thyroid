{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np \t\n",
    "from skimage import io\n",
    "import skimage.morphology as morph\n",
    "import skimage.color as color\n",
    "import skimage.measure as measure\n",
    "import skimage.feature as feature\n",
    "import skimage.util as util\n",
    "from sklearn.feature_extraction.image import extract_patches_2d \n",
    "from scipy.fftpack import dctn\n",
    "from scipy.fftpack import idctn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define paths to data folder and the processed data folder\n",
    "data_path = os.path.join(\".\", \"Data\")\n",
    "data_processed_path = os.path.join(\".\", \"Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max tick-bar distance in pixels\n",
    "\n",
    "tick_bar_dist = []\n",
    "\n",
    "for img_file in sorted(os.listdir(data_path)):\n",
    "    \n",
    "    # Ignore image files that aren't .jpg files (images)\n",
    "    if img_file[-4:] != '.tif':\n",
    "        continue\n",
    "    \n",
    "    # Store path for current image\n",
    "    path_img = os.path.join(data_path, img_file)\n",
    "    \n",
    "    # Read image file\n",
    "    img = cv2.imread(path_img)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold image to form a binary image\n",
    "    # Label the binary image and retain (crop image) the connected component with largest area\n",
    "    \n",
    "    ret,thresh = cv2.threshold(gray, 0, 255, 0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, \n",
    "                                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    cnt=contours[max_index]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop_img_for_tick_bar = gray[y:y+h, x+20:x+w+40]\n",
    "    \n",
    "    # Crop the right 80% of the image to detect tick bar\n",
    "    crop_img_h, crop_img_w = crop_img_for_tick_bar.shape\n",
    "    img_tick = crop_img_for_tick_bar[:, int(0.7*crop_img_w):crop_img_w]\n",
    "    \n",
    "    # Detect the column containing tick bar by estimating intensity peaks\n",
    "    img_tick_h, img_tick_w = img_tick.shape\n",
    "    peaks = []\n",
    "\n",
    "    for i in range(0, img_tick_w-1, 1):\n",
    "        col = img_tick[:, i]\n",
    "        peak_pts = feature.peak.peak_local_max(col, min_distance=10, threshold_abs=250, num_peaks=100)\n",
    "        if peak_pts.shape[0] > 10 and peak_pts.shape[0] < 25:\n",
    "            peaks = peak_pts\n",
    "            column = i\n",
    "            break\n",
    "            \n",
    "    # Measure the tick bar distance in pixels\n",
    "    tick_distance_px = np.max(peaks) - np.min(peaks)\n",
    "    \n",
    "    # Store the tick bar distance\n",
    "    tick_bar_dist.append(tick_distance_px)\n",
    "\n",
    "# Calculate the maximum tick bar distance\n",
    "max_tick_bar_dist_px = np.max(tick_bar_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images\n",
    "\n",
    "i = 0\n",
    "for img_file in sorted(os.listdir(data_path)):\n",
    "    # Ignore image files that aren't .jpg files (images)\n",
    "    if img_file[-4:] != '.tif':\n",
    "        continue\n",
    "    \n",
    "    # Store path for current image\n",
    "    path_img = os.path.join(data_path, img_file)\n",
    "    \n",
    "    # Read image file\n",
    "    img = cv2.imread(path_img)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold image to form a binary image\n",
    "    # Label the binary image and retain (crop image) the connected component with largest area\n",
    "    ret,thresh = cv2.threshold(gray, 0, 255, 0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, \n",
    "                                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    cnt=contours[max_index]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop_img = gray[y:y+h, x+20:x+w-10]\n",
    "    \n",
    "    # Histogram of image\n",
    "    img_hist, bin_edges = np.histogram(crop_img, bins=256, range=(0, 255))\n",
    "    \n",
    "    # Divide graylevel of histogram into 3 parts (0:100; 101:200; 201:255)\n",
    "    \n",
    "    #hist_1 = img_hist[0:101]\n",
    "    #hist_2 = img_hist[101:201]\n",
    "    hist_3 = img_hist[201:256]\n",
    "    \n",
    "    # Find the histogram peak at each of the three divided parts\n",
    "    #hist_1_peak = np.argmax(hist_1)+1\n",
    "    #hist_2_peak = np.argmax(hist_2)+101\n",
    "    hist_3_peak = np.argmax(hist_3)+201\n",
    "    \n",
    "    # Declare a binary mask (initially all zeros) of same size as the cropped image\n",
    "    bin_mask = np.zeros_like(crop_img, dtype=bool)\n",
    "    \n",
    "    # Get all the x,y co-ordinates where the cropped image has the same intensity as the histogram peaks\n",
    "    #pts_1 = np.where(crop_img == hist_1_peak)\n",
    "    #pts_1 = np.transpose(np.vstack(pts_1))\n",
    "    \n",
    "    #pts_2 = np.where(crop_img == hist_2_peak)\n",
    "    #pts_2 = np.transpose(np.vstack(pts_2))\n",
    "    \n",
    "    pts_3 = np.where(crop_img == hist_3_peak)\n",
    "    pts_3 = np.transpose(np.vstack(pts_3))\n",
    "    \n",
    "    # Assign all the x,y points collected as 1 (True) in binary mask\n",
    "    #for r,c in pts_1:\n",
    "        #bin_mask[r, c] = True\n",
    "        \n",
    "    #for r,c in pts_2:\n",
    "        #bin_mask[r, c] = True\n",
    "    \n",
    "    for r,c in pts_3:\n",
    "        bin_mask[r, c] = True\n",
    "        \n",
    "    # Perform dilation of binary mask using a 3 X 3 structuring element\n",
    "    #bin_mask_dil = morph.binary_dilation(bin_mask, selem=morph.square(3, dtype=bool))\n",
    "    \n",
    "    # Invert binary mask\n",
    "    bin_mask_inv = np.invert(bin_mask)\n",
    "    \n",
    "    # Multiply binary mask with cropped image to remove predicted artifacts\n",
    "    out_img = crop_img*bin_mask_inv\n",
    "    \n",
    "    # Restore the \"gap\" after removing the artifacts pixels by simulating the surrounding textures\n",
    "\n",
    "    # Pad the image so to get inter number of 8 X 8 blocks\n",
    "    r, c = out_img.shape\n",
    "    r_pad = 8 - (r % 8)\n",
    "    c_pad = 8 - (c % 8)\n",
    "    \n",
    "    r_pad_l = int(np.floor(r_pad/2))\n",
    "    r_pad_r = int(np.ceil(r_pad/2))\n",
    "    \n",
    "    c_pad_l = int(np.floor(c_pad/2))\n",
    "    c_pad_r = int(np.ceil(c_pad/2))\n",
    "    \n",
    "    out_img_pad = np.pad(crop_img, ((r_pad_l, r_pad_r), (c_pad_l, c_pad_r)), mode='symmetric')\n",
    "    \n",
    "    row_pad = out_img_pad.shape[0]\n",
    "    col_pad = out_img_pad.shape[1]\n",
    "    \n",
    "    # Compute the two-dimensional DCT of 8-by-8 blocks in the image\n",
    "    mask = [[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "            \n",
    "    idct_img = np.zeros_like(out_img_pad)\n",
    "    \n",
    "    for row in range(0, row_pad-1, 8):\n",
    "        for col in range(0, col_pad-1, 8):\n",
    "            img_patch = out_img_pad[row:row+8, col:col+8]\n",
    "            dct_img_patch = dctn(img_patch)\n",
    "            \n",
    "            # Discard all but 10 of the 64 DCT coefficients in each block and compute the Inverse DCT\n",
    "            dct_img_patch = dct_img_patch*mask\n",
    "            \n",
    "            # Inverse DCT\n",
    "            idct_img[row:row+8, col:col+8] = idctn(dct_img_patch)\n",
    "            \n",
    "    # Reduce the Inverse DCT image to same size as the original\n",
    "    idct_img = idct_img[r_pad_l:row_pad-r_pad_r, c_pad_l:col_pad-c_pad_r]\n",
    "    \n",
    "    # Only the \"gaps\" are replaced by the approximated textures, preserve the original textures\n",
    "    corr_img = (idct_img*bin_mask)+out_img\n",
    "    \n",
    "    # Resize the corrected image\n",
    "    corr_res_img = cv2.resize(corr_img, (int((max_tick_bar_dist_px/tick_bar_dist[i])*corr_img.shape[0]), \n",
    "                                             corr_img.shape[1]), interpolation = cv2.INTER_CUBIC)\n",
    "    i = i+1\n",
    "    \n",
    "    # Save the processed image\n",
    "    save_img_path = os.path.join(data_processed_path, img_file)\n",
    "    cv2.imwrite(save_img_path, corr_res_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images without calliper marker info\n",
    "\n",
    "# Define paths to data folder and the processed data folder\n",
    "data_path = os.path.join(\".\", \"Data_without_calliper_info\")\n",
    "data_processed_path = os.path.join(\".\", \"Processed\")\n",
    "\n",
    "for img_file in sorted(os.listdir(data_path)):\n",
    "    # Ignore image files that aren't .jpg files (images)\n",
    "    if img_file[-4:] != '.tif':\n",
    "        continue\n",
    "    \n",
    "    # Store path for current image\n",
    "    path_img = os.path.join(data_path, img_file)\n",
    "    \n",
    "    # Read image file\n",
    "    img = cv2.imread(path_img)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold image to form a binary image\n",
    "    # Label the binary image and retain (crop image) the connected component with largest area\n",
    "    ret,thresh = cv2.threshold(gray, 0, 255, 0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, \n",
    "                                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    max_index = np.argmax(areas)\n",
    "    cnt=contours[max_index]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop_img = gray[y:y+h, x+20:x+w-10]\n",
    "    \n",
    "    # Histogram of image\n",
    "    img_hist, bin_edges = np.histogram(crop_img, bins=256, range=(0, 255))\n",
    "    \n",
    "    # Divide graylevel of histogram into 3 parts (0:100; 101:200; 201:255)\n",
    "    \n",
    "    #hist_1 = img_hist[0:101]\n",
    "    #hist_2 = img_hist[101:201]\n",
    "    hist_3 = img_hist[201:256]\n",
    "    \n",
    "    # Find the histogram peak at each of the three divided parts\n",
    "    #hist_1_peak = np.argmax(hist_1)+1\n",
    "    #hist_2_peak = np.argmax(hist_2)+101\n",
    "    hist_3_peak = np.argmax(hist_3)+201\n",
    "    \n",
    "    # Declare a binary mask (initially all zeros) of same size as the cropped image\n",
    "    bin_mask = np.zeros_like(crop_img, dtype=bool)\n",
    "    \n",
    "    # Get all the x,y co-ordinates where the cropped image has the same intensity as the histogram peaks\n",
    "    #pts_1 = np.where(crop_img == hist_1_peak)\n",
    "    #pts_1 = np.transpose(np.vstack(pts_1))\n",
    "    \n",
    "    #pts_2 = np.where(crop_img == hist_2_peak)\n",
    "    #pts_2 = np.transpose(np.vstack(pts_2))\n",
    "    \n",
    "    pts_3 = np.where(crop_img == hist_3_peak)\n",
    "    pts_3 = np.transpose(np.vstack(pts_3))\n",
    "    \n",
    "    # Assign all the x,y points collected as 1 (True) in binary mask\n",
    "    #for r,c in pts_1:\n",
    "        #bin_mask[r, c] = True\n",
    "        \n",
    "    #for r,c in pts_2:\n",
    "        #bin_mask[r, c] = True\n",
    "    \n",
    "    for r,c in pts_3:\n",
    "        bin_mask[r, c] = True\n",
    "        \n",
    "    # Perform dilation of binary mask using a 3 X 3 structuring element\n",
    "    #bin_mask_dil = morph.binary_dilation(bin_mask, selem=morph.square(3, dtype=bool))\n",
    "    \n",
    "    # Invert binary mask\n",
    "    bin_mask_inv = np.invert(bin_mask)\n",
    "    \n",
    "    # Multiply binary mask with cropped image to remove predicted artifacts\n",
    "    out_img = crop_img*bin_mask_inv\n",
    "    \n",
    "    # Restore the \"gap\" after removing the artifacts pixels by simulating the surrounding textures\n",
    "\n",
    "    # Pad the image so to get inter number of 8 X 8 blocks\n",
    "    r, c = out_img.shape\n",
    "    r_pad = 8 - (r % 8)\n",
    "    c_pad = 8 - (c % 8)\n",
    "    \n",
    "    r_pad_l = int(np.floor(r_pad/2))\n",
    "    r_pad_r = int(np.ceil(r_pad/2))\n",
    "    \n",
    "    c_pad_l = int(np.floor(c_pad/2))\n",
    "    c_pad_r = int(np.ceil(c_pad/2))\n",
    "    \n",
    "    out_img_pad = np.pad(crop_img, ((r_pad_l, r_pad_r), (c_pad_l, c_pad_r)), mode='symmetric')\n",
    "    \n",
    "    row_pad = out_img_pad.shape[0]\n",
    "    col_pad = out_img_pad.shape[1]\n",
    "    \n",
    "    # Compute the two-dimensional DCT of 8-by-8 blocks in the image\n",
    "    mask = [[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "            \n",
    "    idct_img = np.zeros_like(out_img_pad)\n",
    "    \n",
    "    for row in range(0, row_pad-1, 8):\n",
    "        for col in range(0, col_pad-1, 8):\n",
    "            img_patch = out_img_pad[row:row+8, col:col+8]\n",
    "            dct_img_patch = dctn(img_patch)\n",
    "            \n",
    "            # Discard all but 10 of the 64 DCT coefficients in each block and compute the Inverse DCT\n",
    "            dct_img_patch = dct_img_patch*mask\n",
    "            \n",
    "            # Inverse DCT\n",
    "            idct_img[row:row+8, col:col+8] = idctn(dct_img_patch)\n",
    "            \n",
    "    # Reduce the Inverse DCT image to same size as the original\n",
    "    idct_img = idct_img[r_pad_l:row_pad-r_pad_r, c_pad_l:col_pad-c_pad_r]\n",
    "    \n",
    "    # Only the \"gaps\" are replaced by the approximated textures, preserve the original textures\n",
    "    corr_img = (idct_img*bin_mask)+out_img\n",
    "    \n",
    "    # Resize the corrected image\n",
    "    corr_res_img = cv2.resize(corr_img, (300, 250), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Save the processed image\n",
    "    save_img_path = os.path.join(data_processed_path, img_file)\n",
    "    cv2.imwrite(save_img_path, corr_res_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
